# deployment/production/docker-compose.yml
# Production Deployment Configuration for AQP Sharpe >2.0 System

version: '3.8'

services:
  # Core AQP Master Engine
  aqp-master:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile.aqp-master
    container_name: aqp-master-engine
    environment:
      - ENVIRONMENT=production
      - TARGET_SHARPE=2.0
      - NUM_STRATEGIES=6
      - INITIAL_CAPITAL=100000
      - MONITORING_ENABLED=true
      - AUTO_REBALANCE=true
      - LOG_LEVEL=INFO
    env_file:
      - .env.production
    volumes:
      - aqp-data:/app/data
      - aqp-logs:/app/logs
      - aqp-config:/app/config
    ports:
      - "8000:8000"  # API port
    networks:
      - aqp-network
    depends_on:
      - redis
      - postgres
      - prometheus
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Strategy Generation Service
  strategy-generator:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile.strategy-generator
    container_name: aqp-strategy-generator
    environment:
      - ENVIRONMENT=production
      - LLM_PARALLEL_REQUESTS=4
      - STRATEGY_CACHE_SIZE=100
    env_file:
      - .env.production
    volumes:
      - aqp-strategies:/app/strategies
      - aqp-logs:/app/logs
    networks:
      - aqp-network
    depends_on:
      - redis
    restart: unless-stopped
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '2.0'
          memory: 4G

  # Ensemble Optimizer Service
  ensemble-optimizer:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile.ensemble-optimizer
    container_name: aqp-ensemble-optimizer
    environment:
      - ENVIRONMENT=production
      - OPTIMIZATION_TIMEOUT=300
      - MAX_STRATEGIES=20
    env_file:
      - .env.production
    volumes:
      - aqp-data:/app/data
      - aqp-logs:/app/logs
    networks:
      - aqp-network
    depends_on:
      - postgres
      - redis
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G

  # Real-time Performance Monitor
  performance-monitor:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile.performance-monitor
    container_name: aqp-performance-monitor
    environment:
      - ENVIRONMENT=production
      - MONITOR_INTERVAL=60
      - ALERT_THRESHOLD_SHARPE=1.8
      - REBALANCE_THRESHOLD=0.3
    env_file:
      - .env.production
    volumes:
      - aqp-data:/app/data
      - aqp-logs:/app/logs
    networks:
      - aqp-network
    depends_on:
      - postgres
      - redis
      - prometheus
    restart: unless-stopped

  # Data Aggregator Service (from previous artifacts)
  data-aggregator:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile.data-aggregator
    container_name: aqp-data-aggregator
    environment:
      - ENVIRONMENT=production
      - DATA_REFRESH_INTERVAL=300
      - CACHE_EXPIRY=3600
    env_file:
      - .env.production
    volumes:
      - aqp-data:/app/data
      - aqp-logs:/app/logs
    networks:
      - aqp-network
    depends_on:
      - redis
    restart: unless-stopped

  # Backtesting Engine (from previous artifacts)
  backtesting-engine:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile.backtesting
    container_name: aqp-backtesting-engine
    environment:
      - ENVIRONMENT=production
      - PARALLEL_BACKTESTS=4
      - BACKTEST_TIMEOUT=600
    env_file:
      - .env.production
    volumes:
      - aqp-data:/app/data
      - aqp-logs:/app/logs
    networks:
      - aqp-network
    depends_on:
      - postgres
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G

  # API Gateway
  api-gateway:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile.api-gateway
    container_name: aqp-api-gateway
    environment:
      - ENVIRONMENT=production
      - RATE_LIMIT=1000
      - AUTH_ENABLED=true
    env_file:
      - .env.production
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./ssl:/app/ssl:ro
      - aqp-logs:/app/logs
    networks:
      - aqp-network
    depends_on:
      - aqp-master
    restart: unless-stopped

  # Database Services
  postgres:
    image: postgres:15
    container_name: aqp-postgres
    environment:
      - POSTGRES_DB=aqp_production
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./sql/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    networks:
      - aqp-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d aqp_production"]
      interval: 30s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: aqp-redis
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis-data:/data
    networks:
      - aqp-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 5s
      retries: 5

  # Monitoring Stack
  prometheus:
    image: prom/prometheus:latest
    container_name: aqp-prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - aqp-network
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: aqp-grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    ports:
      - "3000:3000"
    networks:
      - aqp-network
    depends_on:
      - prometheus
    restart: unless-stopped

  # Log Aggregation
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    container_name: aqp-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - aqp-network
    restart: unless-stopped

  logstash:
    image: docker.elastic.co/logstash/logstash:8.8.0
    container_name: aqp-logstash
    volumes:
      - ./monitoring/logstash/pipeline:/usr/share/logstash/pipeline:ro
      - aqp-logs:/app/logs:ro
    networks:
      - aqp-network
    depends_on:
      - elasticsearch
    restart: unless-stopped

  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.0
    container_name: aqp-kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    networks:
      - aqp-network
    depends_on:
      - elasticsearch
    restart: unless-stopped

  # Alerting
  alertmanager:
    image: prom/alertmanager:latest
    container_name: aqp-alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    volumes:
      - ./monitoring/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager-data:/alertmanager
    ports:
      - "9093:9093"
    networks:
      - aqp-network
    restart: unless-stopped

  # Message Queue for Async Processing
  rabbitmq:
    image: rabbitmq:3-management
    container_name: aqp-rabbitmq
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_USER}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD}
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    networks:
      - aqp-network
    restart: unless-stopped

  # Worker Services for Async Tasks
  worker-strategy:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile.worker
    container_name: aqp-worker-strategy
    environment:
      - WORKER_TYPE=strategy_generation
      - WORKER_CONCURRENCY=4
    env_file:
      - .env.production
    volumes:
      - aqp-data:/app/data
      - aqp-logs:/app/logs
    networks:
      - aqp-network
    depends_on:
      - rabbitmq
      - redis
    restart: unless-stopped
    deploy:
      replicas: 2

  worker-backtest:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile.worker
    container_name: aqp-worker-backtest
    environment:
      - WORKER_TYPE=backtesting
      - WORKER_CONCURRENCY=2
    env_file:
      - .env.production
    volumes:
      - aqp-data:/app/data
      - aqp-logs:/app/logs
    networks:
      - aqp-network
    depends_on:
      - rabbitmq
      - postgres
    restart: unless-stopped
    deploy:
      replicas: 3

# Networks
networks:
  aqp-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# Volumes
volumes:
  aqp-data:
    driver: local
  aqp-logs:
    driver: local
  aqp-config:
    driver: local
  aqp-strategies:
    driver: local
  postgres-data:
    driver: local
  redis-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  elasticsearch-data:
    driver: local
  alertmanager-data:
    driver: local
  rabbitmq-data:
    driver: local

---
# deployment/production/.env.production.example
# Production Environment Configuration

# System Configuration
ENVIRONMENT=production
TARGET_SHARPE=2.0
NUM_STRATEGIES=6
INITIAL_CAPITAL=100000
MONITORING_ENABLED=true
AUTO_REBALANCE=true

# Database Configuration
POSTGRES_USER=aqp_user
POSTGRES_PASSWORD=your_secure_postgres_password
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=aqp_production

# Redis Configuration
REDIS_PASSWORD=your_secure_redis_password
REDIS_HOST=redis
REDIS_PORT=6379

# RabbitMQ Configuration
RABBITMQ_USER=aqp_user
RABBITMQ_PASSWORD=your_secure_rabbitmq_password

# Monitoring Configuration
GRAFANA_PASSWORD=your_secure_grafana_password

# LLM API Keys
ANTHROPIC_API_KEY=your_anthropic_api_key
OPENAI_API_KEY=your_openai_api_key
GOOGLE_API_KEY=your_google_api_key
GROK_API_KEY=your_grok_api_key

# Data Provider API Keys
ALPHA_VANTAGE_API_KEY=your_alpha_vantage_key
POLYGON_API_KEY=your_polygon_key
QUANDL_API_KEY=your_quandl_key

# AWS Configuration (if using AWS services)
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_REGION=us-east-1
AWS_S3_BUCKET=aqp-production-data

# Security
JWT_SECRET_KEY=your_jwt_secret_key
API_RATE_LIMIT=1000
ALLOWED_HOSTS=your-domain.com,localhost

# Alerting Configuration
SLACK_WEBHOOK_URL=https://hooks.slack.com/your/webhook/url
EMAIL_SMTP_SERVER=smtp.gmail.com
EMAIL_SMTP_PORT=587
EMAIL_USERNAME=your_email@gmail.com
EMAIL_PASSWORD=your_email_app_password

# Risk Management
MAX_DRAWDOWN_ALERT=0.08
EMERGENCY_STOP_DRAWDOWN=0.15
POSITION_SIZE_LIMIT=0.35
CORRELATION_THRESHOLD=0.6

# Performance Monitoring
PERFORMANCE_CHECK_INTERVAL=300
REBALANCE_CHECK_INTERVAL=3600
DAILY_REPORT_TIME=09:30

# Logging
LOG_LEVEL=INFO
LOG_RETENTION_DAYS=30

---
# deployment/scripts/deploy-production.sh
#!/bin/bash

# Production Deployment Script for AQP Sharpe >2.0 System

set -e

echo "🚀 Deploying AQP Production System for Sharpe >2.0"
echo "=================================================="

# Configuration
DEPLOYMENT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
PRODUCTION_DIR="$DEPLOYMENT_DIR/production"
ENV_FILE="$PRODUCTION_DIR/.env.production"

# Pre-deployment checks
echo "📋 Pre-deployment checks..."

# Check if environment file exists
if [ ! -f "$ENV_FILE" ]; then
    echo "❌ Production environment file not found: $ENV_FILE"
    echo "   Please copy .env.production.example to .env.production and configure"
    exit 1
fi

# Check Docker and Docker Compose
if ! command -v docker &> /dev/null; then
    echo "❌ Docker not found. Please install Docker."
    exit 1
fi

if ! command -v docker-compose &> /dev/null; then
    echo "❌ Docker Compose not found. Please install Docker Compose."
    exit 1
fi

# Check required API keys
echo "🔑 Checking API keys..."
source "$ENV_FILE"

required_keys=(
    "ANTHROPIC_API_KEY"
    "OPENAI_API_KEY" 
    "ALPHA_VANTAGE_API_KEY"
    "POSTGRES_PASSWORD"
    "REDIS_PASSWORD"
)

for key in "${required_keys[@]}"; do
    if [ -z "${!key}" ]; then
        echo "❌ Missing required environment variable: $key"
        exit 1
    fi
done

echo "✅ All required API keys present"

# Build and deploy
echo "🔨 Building Docker images..."
cd "$PRODUCTION_DIR"

# Pull latest base images
docker-compose pull

# Build custom images
docker-compose build --parallel

echo "🚀 Starting AQP production deployment..."

# Start infrastructure services first
echo "📊 Starting infrastructure services..."
docker-compose up -d postgres redis rabbitmq elasticsearch

# Wait for infrastructure to be ready
echo "⏳ Waiting for infrastructure to be ready..."
sleep 30

# Health check for infrastructure
echo "🏥 Health checking infrastructure..."
docker-compose exec postgres pg_isready -U "$POSTGRES_USER" -d "$POSTGRES_DB"
docker-compose exec redis redis-cli ping

# Start monitoring services
echo "📈 Starting monitoring services..."
docker-compose up -d prometheus grafana alertmanager logstash kibana

# Start core AQP services
echo "🎯 Starting core AQP services..."
docker-compose up -d data-aggregator backtesting-engine ensemble-optimizer
sleep 10

docker-compose up -d strategy-generator performance-monitor
sleep 10

docker-compose up -d aqp-master api-gateway

# Start worker services
echo "👷 Starting worker services..."
docker-compose up -d worker-strategy worker-backtest

# Final health check
echo "🏥 Final health check..."
sleep 30

# Check service health
services=(
    "aqp-master-engine"
    "aqp-postgres" 
    "aqp-redis"
    "aqp-prometheus"
    "aqp-grafana"
)

all_healthy=true
for service in "${services[@]}"; do
    if [ "$(docker inspect -f '{{.State.Health.Status}}' "$service" 2>/dev/null)" != "healthy" ]; then
        if [ "$(docker inspect -f '{{.State.Status}}' "$service" 2>/dev/null)" != "running" ]; then
            echo "❌ Service $service is not running"
            all_healthy=false
        else
            echo "⚠️  Service $service is running but health check pending"
        fi
    else
        echo "✅ Service $service is healthy"
    fi
done

# Initialize the system
echo "🎯 Initializing AQP system..."
docker-compose exec aqp-master python -c "
import asyncio
from aqp_master_engine import AQPMasterEngine, AQPConfig

async def initialize():
    config = AQPConfig(target_sharpe=2.0, num_strategies=6)
    engine = AQPMasterEngine(config)
    result = await engine.initialize_system()
    print(f'Initialization: {result[\"status\"]}')
    if result['status'] in ['success', 'partial_success']:
        sharpe = result['performance_metrics']['ensemble_sharpe']
        print(f'Achieved Sharpe: {sharpe:.2f}')
        if sharpe >= 2.0:
            print('🎉 TARGET ACHIEVED: Sharpe >2.0!')
        else:
            print('📈 In progress towards Sharpe >2.0')
    return result

asyncio.run(initialize())
"

if [ "$all_healthy" = true ]; then
    echo ""
    echo "🎉 AQP PRODUCTION DEPLOYMENT SUCCESSFUL!"
    echo "======================================"
    echo "✅ All services are running and healthy"
    echo "🎯 System initialized and targeting Sharpe >2.0"
    echo ""
    echo "📊 Access Points:"
    echo "   - Main API: http://localhost:8000"
    echo "   - Grafana: http://localhost:3000 (admin/password from env)"
    echo "   - Prometheus: http://localhost:9090"
    echo "   - Kibana: http://localhost:5601"
    echo "   - RabbitMQ: http://localhost:15672"
    echo ""
    echo "🎯 Next Steps:"
    echo "   1. Check Grafana dashboards for performance metrics"
    echo "   2. Monitor Sharpe ratio achievement in real-time"
    echo "   3. Review alerts and ensure monitoring is active"
    echo "   4. Begin live trading operations"
    echo ""
else
    echo ""
    echo "⚠️  DEPLOYMENT COMPLETED WITH WARNINGS"
    echo "===================================="
    echo "Some services may still be starting up."
    echo "Check individual service logs with:"
    echo "docker-compose logs <service-name>"
fi

echo "📋 Deployment Summary:"
docker-compose ps

---
# deployment/scripts/health-check.sh
#!/bin/bash

# Health Check Script for AQP Production System

echo "🏥 AQP System Health Check"
echo "=========================="

cd "$(dirname "${BASH_SOURCE[0]}")/../production"

# Service status check
echo "📊 Service Status:"
docker-compose ps

echo ""
echo "🎯 Core AQP Services Health:"

# Check AQP Master Engine
echo -n "Master Engine: "
if curl -f -s http://localhost:8000/health > /dev/null; then
    echo "✅ Healthy"
else
    echo "❌ Unhealthy"
fi

# Check API responsiveness
echo -n "API Response: "
if curl -f -s http://localhost:8000/api/v1/status > /dev/null; then
    echo "✅ Responding"
else
    echo "❌ Not responding"
fi

# Check Sharpe achievement
echo -n "Sharpe Status: "
sharpe_status=$(curl -s http://localhost:8000/api/v1/performance/sharpe 2>/dev/null | jq -r '.current_sharpe // 0' 2>/dev/null)
if (( $(echo "$sharpe_status >= 2.0" | bc -l) )); then
    echo "🎯 TARGET ACHIEVED: $sharpe_status"
elif (( $(echo "$sharpe_status >= 1.8" | bc -l) )); then
    echo "📈 In Progress: $sharpe_status"
else
    echo "⚠️  Below Target: $sharpe_status"
fi

echo ""
echo "📈 Monitoring Services:"

# Check Prometheus
echo -n "Prometheus: "
if curl -f -s http://localhost:9090/-/healthy > /dev/null; then
    echo "✅ Healthy"
else
    echo "❌ Unhealthy"
fi

# Check Grafana
echo -n "Grafana: "
if curl -f -s http://localhost:3000/api/health > /dev/null; then
    echo "✅ Healthy"
else
    echo "❌ Unhealthy"
fi

echo ""
echo "💾 Data Services:"

# Check PostgreSQL
echo -n "PostgreSQL: "
if docker-compose exec -T postgres pg_isready > /dev/null 2>&1; then
    echo "✅ Healthy"
else
    echo "❌ Unhealthy"
fi

# Check Redis
echo -n "Redis: "
if docker-compose exec -T redis redis-cli ping > /dev/null 2>&1; then
    echo "✅ Healthy"
else
    echo "❌ Unhealthy"
fi

echo ""
echo "📊 Resource Usage:"
docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}" | head -10

echo ""
echo "🔍 Recent Logs (Last 10 lines):"
docker-compose logs --tail=10 aqp-master | head -20