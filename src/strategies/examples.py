# src/strategies/example_strategies.py
# Example trading strategies demonstrating LLM-generated approaches

import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Any
from abc import ABC, abstractmethod
import logging

from backtesting.advanced_backtester import Strategy

logger = logging.getLogger(__name__)

class LLMGeneratedStrategy(Strategy):
    """Base class for LLM-generated strategies"""
    
    def __init__(self, 
                 strategy_code: str,
                 strategy_description: str,
                 model_source: str,
                 parameters: Dict[str, Any]):
        self.strategy_code = strategy_code
        self.strategy_description = strategy_description
        self.model_source = model_source
        self.parameters = parameters
        
    def get_metadata(self) -> Dict[str, Any]:
        """Return strategy metadata"""
        return {
            'description': self.strategy_description,
            'model_source': self.model_source,
            'parameters': self.parameters,
            'strategy_type': 'llm_generated'
        }

class MomentumVolatilityStrategy(LLMGeneratedStrategy):
    """
    Momentum strategy with volatility filtering
    Generated by: Claude (systematic implementation)
    Reviewed by: GPT-4 (consensus validation)
    """
    
    def __init__(self, 
                 lookback_momentum: int = 20,
                 lookback_volatility: int = 60,
                 momentum_threshold: float = 0.02,
                 volatility_percentile: float = 0.3):
        
        super().__init__(
            strategy_code="momentum_volatility_v1",
            strategy_description="Momentum strategy with volatility filtering for risk-adjusted alpha",
            model_source="claude_gpt4_ensemble",
            parameters={
                'lookback_momentum': lookback_momentum,
                'lookback_volatility': lookback_volatility,
                'momentum_threshold': momentum_threshold,
                'volatility_percentile': volatility_percentile
            }
        )
        
        self.lookback_momentum = lookback_momentum
        self.lookback_volatility = lookback_volatility
        self.momentum_threshold = momentum_threshold
        self.volatility_percentile = volatility_percentile
    
    def generate_signals(self, data: pd.DataFrame) -> pd.DataFrame:
        """Generate momentum signals with volatility filter"""
        
        signals = pd.DataFrame(index=data.index)
        
        # Extract symbols
        symbols = list(set([col.split('_')[0] for col in data.columns if '_close' in col]))
        
        for symbol in symbols:
            price_col = f"{symbol}_close"
            volume_col = f"{symbol}_volume"
            
            if price_col not in data.columns:
                continue
                
            prices = data[price_col]
            
            # Calculate momentum
            momentum = prices / prices.shift(self.lookback_momentum) - 1
            
            # Calculate volatility
            returns = prices.pct_change()
            volatility = returns.rolling(window=self.lookback_volatility).std()
            
            # Volatility filter: only trade in low-volatility regimes
            volatility_threshold = volatility.rolling(window=252).quantile(self.volatility_percentile)
            low_vol_filter = volatility <= volatility_threshold
            
            # Generate signals
            raw_signals = np.where(
                momentum > self.momentum_threshold, 1,
                np.where(momentum < -self.momentum_threshold, -1, 0)
            )
            
            # Apply volatility filter
            filtered_signals = np.where(low_vol_filter, raw_signals, 0)
            
            signals[f"{symbol}_signal"] = filtered_signals
        
        return signals.fillna(0)
    
    def calculate_positions(self, signals: pd.DataFrame, data: pd.DataFrame) -> pd.DataFrame:
        """Calculate volatility-adjusted position sizes"""
        
        positions = pd.DataFrame(index=signals.index)
        
        # Extract symbols
        symbols = list(set([col.split('_')[0] for col in signals.columns if '_signal' in col]))
        
        # Calculate volatility-adjusted weights
        for symbol in symbols:
            signal_col = f"{symbol}_signal"
            price_col = f"{symbol}_close"
            
            if signal_col not in signals.columns or price_col not in data.columns:
                continue
            
            # Calculate inverse volatility weights
            returns = data[price_col].pct_change()
            volatility = returns.rolling(window=60).std()
            
            # Inverse volatility weighting
            inv_vol_weights = 1 / volatility
            
            # Normalize weights
            total_inv_vol = inv_vol_weights.rolling(window=1).sum()
            normalized_weights = inv_vol_weights / len(symbols)  # Simple equal weight for now
            
            # Apply signals
            positions[symbol] = signals[signal_col] * normalized_weights * 0.8  # 80% allocation
        
        return positions.fillna(0)

class MeanReversionStrategy(LLMGeneratedStrategy):
    """
    Statistical mean reversion with regime detection
    Generated by: Grok (creative alpha discovery)
    Implemented by: Claude (systematic implementation)
    """
    
    def __init__(self,
                 lookback_window: int = 20,
                 zscore_threshold: float = 1.5,
                 regime_lookback: int = 252):
        
        super().__init__(
            strategy_code="mean_reversion_regime_v1",
            strategy_description="Statistical arbitrage with regime-aware mean reversion",
            model_source="grok_claude_ensemble",
            parameters={
                'lookback_window': lookback_window,
                'zscore_threshold': zscore_threshold,
                'regime_lookback': regime_lookback
            }
        )
        
        self.lookback_window = lookback_window
        self.zscore_threshold = zscore_threshold
        self.regime_lookback = regime_lookback
    
    def generate_signals(self, data: pd.DataFrame) -> pd.DataFrame:
        """Generate mean reversion signals with regime detection"""
        
        signals = pd.DataFrame(index=data.index)
        
        symbols = list(set([col.split('_')[0] for col in data.columns if '_close' in col]))
        
        for symbol in symbols:
            price_col = f"{symbol}_close"
            
            if price_col not in data.columns:
                continue
                
            prices = data[price_col]
            
            # Calculate rolling statistics
            rolling_mean = prices.rolling(window=self.lookback_window).mean()
            rolling_std = prices.rolling(window=self.lookback_window).std()
            
            # Z-score calculation
            zscore = (prices - rolling_mean) / rolling_std
            
            # Regime detection (volatility-based)
            returns = prices.pct_change()
            long_term_vol = returns.rolling(window=self.regime_lookback).std()
            short_term_vol = returns.rolling(window=20).std()
            
            # Mean reversion works better in low volatility regimes
            vol_ratio = short_term_vol / long_term_vol
            low_vol_regime = vol_ratio < 1.2
            
            # Generate signals
            raw_signals = np.where(
                zscore < -self.zscore_threshold, 1,  # Oversold -> Buy
                np.where(zscore > self.zscore_threshold, -1, 0)  # Overbought -> Sell
            )
            
            # Apply regime filter
            regime_filtered_signals = np.where(low_vol_regime, raw_signals, 0)
            
            signals[f"{symbol}_signal"] = regime_filtered_signals
        
        return signals.fillna(0)
    
    def calculate_positions(self, signals: pd.DataFrame, data: pd.DataFrame) -> pd.DataFrame:
        """Calculate position sizes based on signal strength"""
        
        positions = pd.DataFrame(index=signals.index)
        
        symbols = list(set([col.split('_')[0] for col in signals.columns if '_signal' in col]))
        
        for symbol in symbols:
            signal_col = f"{symbol}_signal"
            
            if signal_col not in signals.columns:
                continue
            
            # Simple equal weight allocation
            positions[symbol] = signals[signal_col] / len(symbols) * 0.6  # 60% allocation
        
        return positions.fillna(0)

class CrossAssetMomentumStrategy(LLMGeneratedStrategy):
    """
    Cross-asset momentum with currency hedging
    Generated by: GPT-4 (consensus building)
    Optimized by: Gemini (risk validation)
    """
    
    def __init__(self,
                 short_window: int = 5,
                 long_window: int = 20,
                 volatility_lookback: int = 60):
        
        super().__init__(
            strategy_code="cross_asset_momentum_v1",
            strategy_description="Cross-asset momentum with dynamic hedging",
            model_source="gpt4_gemini_ensemble",
            parameters={
                'short_window': short_window,
                'long_window': long_window,
                'volatility_lookback': volatility_lookback
            }
        )
        
        self.short_window = short_window
        self.long_window = long_window
        self.volatility_lookback = volatility_lookback
    
    def generate_signals(self, data: pd.DataFrame) -> pd.DataFrame:
        """Generate cross-asset momentum signals"""
        
        signals = pd.DataFrame(index=data.index)
        
        symbols = list(set([col.split('_')[0] for col in data.columns if '_close' in col]))
        
        # Calculate relative momentum across assets
        momentum_scores = pd.DataFrame(index=data.index)
        
        for symbol in symbols:
            price_col = f"{symbol}_close"
            
            if price_col not in data.columns:
                continue
                
            prices = data[price_col]
            
            # Dual moving average momentum
            short_ma = prices.rolling(window=self.short_window).mean()
            long_ma = prices.rolling(window=self.long_window).mean()
            
            momentum_scores[symbol] = (short_ma / long_ma) - 1
        
        # Rank-based signals
        for symbol in symbols:
            if symbol not in momentum_scores.columns:
                continue
                
            # Cross-sectional ranking
            ranks = momentum_scores.rank(axis=1, pct=True)
            
            # Top quartile long, bottom quartile short
            raw_signals = np.where(
                ranks[symbol] > 0.75, 1,
                np.where(ranks[symbol] < 0.25, -1, 0)
            )
            
            signals[f"{symbol}_signal"] = raw_signals
        
        return signals.fillna(0)
    
    def calculate_positions(self, signals: pd.DataFrame, data: pd.DataFrame) -> pd.DataFrame:
        """Calculate risk-parity weighted positions"""
        
        positions = pd.DataFrame(index=signals.index)
        
        symbols = list(set([col.split('_')[0] for col in signals.columns if '_signal' in col]))
        
        # Calculate volatility-adjusted weights
        volatilities = {}
        for symbol in symbols:
            price_col = f"{symbol}_close"
            if price_col in data.columns:
                returns = data[price_col].pct_change()
                volatilities[symbol] = returns.rolling(window=self.volatility_lookback).std()
        
        for symbol in symbols:
            signal_col = f"{symbol}_signal"
            
            if signal_col not in signals.columns or symbol not in volatilities:
                continue
            
            # Risk parity weight (inverse volatility)
            total_inv_vol = sum(1/vol.iloc[-1] for vol in volatilities.values() if not pd.isna(vol.iloc[-1]))
            weight = (1 / volatilities[symbol]) / total_inv_vol if total_inv_vol > 0 else 1/len(symbols)
            
            positions[symbol] = signals[signal_col] * weight * 0.9  # 90% allocation
        
        return positions.fillna(0)

# ========================================
# LLM STRATEGY GENERATOR
# ========================================

class LLMStrategyGenerator:
    """Generate strategies using LLM ensemble"""
    
    def __init__(self, aqp_platform):
        self.aqp_platform = aqp_platform
        
    async def generate_strategy(self, 
                              description: str,
                              symbols: List[str],
                              target_sharpe: float = 2.0,
                              preferred_models: List[str] = None) -> LLMGeneratedStrategy:
        """Generate a custom strategy using LLM ensemble"""
        
        # Use the AQP platform to generate strategy
        result = await self.aqp_platform.run_research_cycle(
            query=description,
            target_sharpe=target_sharpe,
            symbols=symbols,
            preferred_models=preferred_models or ['claude', 'gpt4', 'grok']
        )
        
        # Parse the generated strategy code
        strategy_class = self._parse_strategy_code(result['strategy_code'])
        
        return strategy_class(
            strategy_code=result['strategy_code'],
            strategy_description=description,
            model_source=','.join(result['models_used']),
            parameters=result.get('parameters', {})
        )
    
    def _parse_strategy_code(self, code: str) -> type:
        """Parse LLM-generated strategy code into executable class"""
        
        # This would involve more sophisticated code parsing and validation
        # For now, return a dynamic strategy class
        
        class DynamicLLMStrategy(LLMGeneratedStrategy):
            def __init__(self, **kwargs):
                super().__init__(**kwargs)
                # Execute the LLM-generated code safely
                self._strategy_code = code
            
            def generate_signals(self, data: pd.DataFrame) -> pd.DataFrame:
                # Execute LLM-generated signal logic
                # This would need proper sandboxing and validation
                return self._execute_signal_logic(data)
            
            def calculate_positions(self, signals: pd.DataFrame, data: pd.DataFrame) -> pd.DataFrame:
                # Execute LLM-generated position logic
                return self._execute_position_logic(signals, data)
            
            def _execute_signal_logic(self, data: pd.DataFrame) -> pd.DataFrame:
                # Placeholder for safe code execution
                signals = pd.DataFrame(index=data.index)
                symbols = list(set([col.split('_')[0] for col in data.columns if '_close' in col]))
                
                for symbol in symbols:
                    signals[f"{symbol}_signal"] = np.random.choice([-1, 0, 1], size=len(data))
                
                return signals
            
            def _execute_position_logic(self, signals: pd.DataFrame, data: pd.DataFrame) -> pd.DataFrame:
                # Placeholder for safe code execution
                positions = pd.DataFrame(index=signals.index)
                symbols = list(set([col.split('_')[0] for col in signals.columns if '_signal' in col]))
                
                for symbol in symbols:
                    signal_col = f"{symbol}_signal"
                    if signal_col in signals.columns:
                        positions[symbol] = signals[signal_col] / len(symbols) * 0.5
                
                return positions
        
        return DynamicLLMStrategy

# ========================================
# STRATEGY ENSEMBLE
# ========================================

class StrategyEnsemble:
    """Combine multiple strategies for enhanced performance"""
    
    def __init__(self, strategies: List[Strategy], weights: List[float] = None):
        self.strategies = strategies
        self.weights = weights or [1.0 / len(strategies)] * len(strategies)
        
        assert len(self.strategies) == len(self.weights), "Strategies and weights must have same length"
        assert abs(sum(self.weights) - 1.0) < 1e-6, "Weights must sum to 1.0"
    
    def generate_ensemble_signals(self, data: pd.DataFrame) -> pd.DataFrame:
        """Generate weighted ensemble signals"""
        
        all_signals = []
        
        for strategy in self.strategies:
            strategy_signals = strategy.generate_signals(data)
            all_signals.append(strategy_signals)
        
        # Weighted combination
        ensemble_signals = pd.DataFrame(index=data.index)
        
        if all_signals:
            # Get all unique signal columns
            all_columns = set()
            for signals in all_signals:
                all_columns.update(signals.columns)
            
            # Combine signals with weights
            for col in all_columns:
                weighted_signal = pd.Series(0.0, index=data.index)
                
                for signals, weight in zip(all_signals, self.weights):
                    if col in signals.columns:
                        weighted_signal += signals[col] * weight
                
                ensemble_signals[col] = weighted_signal
        
        return ensemble_signals
    
    def calculate_ensemble_positions(self, signals: pd.DataFrame, data: pd.DataFrame) -> pd.DataFrame:
        """Calculate ensemble position allocation"""
        
        # For ensemble, we can use the signals directly for position sizing
        positions = pd.DataFrame(index=signals.index)
        
        symbols = list(set([col.split('_')[0] for col in signals.columns if '_signal' in col]))
        
        for symbol in symbols:
            signal_col = f"{symbol}_signal"
            if signal_col in signals.columns:
                # Apply ensemble signal with volatility adjustment
                price_col = f"{symbol}_close"
                if price_col in data.columns:
                    returns = data[price_col].pct_change()
                    volatility = returns.rolling(window=60).std()
                    
                    # Inverse volatility weighting
                    vol_adj_weight = 1 / volatility if not volatility.isna().all() else 1.0
                    vol_adj_weight = vol_adj_weight / len(symbols)  # Normalize
                    
                    positions[symbol] = signals[signal_col] * vol_adj_weight * 0.95  # 95% allocation
        
        return positions.fillna(0)

# ========================================
# EXAMPLE USAGE
# ========================================

def create_example_strategies() -> List[Strategy]:
    """Create a set of example strategies for testing"""
    
    strategies = [
        MomentumVolatilityStrategy(
            lookback_momentum=20,
            momentum_threshold=0.02,
            volatility_percentile=0.3
        ),
        MeanReversionStrategy(
            lookback_window=15,
            zscore_threshold=1.5
        ),
        CrossAssetMomentumStrategy(
            short_window=5,
            long_window=20
        )
    ]
    
    return strategies

def create_strategy_ensemble() -> StrategyEnsemble:
    """Create an ensemble of example strategies"""
    
    strategies = create_example_strategies()
    
    # Weights based on expected Sharpe ratios
    weights = [0.4, 0.3, 0.3]  # Favor momentum strategies
    
    ensemble = StrategyEnsemble(strategies, weights)
    
    return ensemble

if __name__ == "__main__":
    # Example usage
    print("ðŸŽ¯ AQP Example Strategies")
    print("==========================")
    
    strategies = create_example_strategies()
    
    for i, strategy in enumerate(strategies):
        metadata = strategy.get_metadata()
        print(f"\n{i+1}. {metadata['description']}")
        print(f"   Model Source: {metadata['model_source']}")
        print(f"   Parameters: {metadata['parameters']}")
    
    print(f"\nðŸ“Š Total Strategies: {len(strategies)}")
    print(f"ðŸŽ¯ Target Ensemble Sharpe: >2.0")
    print(f"ðŸš€ Ready for backtesting and deployment!")